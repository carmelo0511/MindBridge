"""
MindBridge Real AI Engine

Int√®gre des mod√®les Hugging Face pour l'analyse de sant√© mentale
Utilise des mod√®les pr√©-entra√Æn√©s avec fine-tuning pour la d√©tection
"""

import torch
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification,
    pipeline, AutoModel, AutoConfig
)
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import Dict, List, Any, Tuple
import logging
import time
from datetime import datetime
import re
import nltk
from textblob import TextBlob
import warnings

warnings.filterwarnings("ignore")
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MentalHealthAI:
    """
    Moteur IA r√©el pour l'analyse de sant√© mentale
    Utilise des mod√®les Transformer fine-tun√©s
    """
    
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"ü§ñ Initialisation sur {self.device}")
        
        # Initialiser les mod√®les
        self.emotion_classifier = None
        self.sentiment_analyzer = None
        self.embedding_model = None
        self.mental_health_classifier = None
        
        # T√©l√©charger les donn√©es NLTK n√©cessaires
        self._download_nltk_data()
        
        # Initialiser les mod√®les
        self._initialize_models()
        
    def _download_nltk_data(self):
        """T√©l√©charge les donn√©es NLTK n√©cessaires"""
        try:
            import nltk
            nltk.download('punkt', quiet=True)
            nltk.download('vader_lexicon', quiet=True)
            nltk.download('stopwords', quiet=True)
        except Exception as e:
            logger.warning(f"Erreur t√©l√©chargement NLTK: {e}")
    
    def _initialize_models(self):
        """Initialise tous les mod√®les d'IA"""
        logger.info("üîÑ Chargement des mod√®les d'IA...")
        
        try:
            # 1. Analyseur de sentiment
            logger.info("üìä Chargement analyseur de sentiment...")
            self.sentiment_analyzer = pipeline(
                "sentiment-analysis",
                model="cardiffnlp/twitter-roberta-base-sentiment-latest",
                device=0 if self.device == "cuda" else -1
            )
            
            # 2. Classificateur d'√©motions
            logger.info("üòä Chargement classificateur d'√©motions...")
            self.emotion_classifier = pipeline(
                "text-classification",
                model="j-hartmann/emotion-english-distilroberta-base",
                device=0 if self.device == "cuda" else -1
            )
            
            # 3. Mod√®le d'embeddings s√©mantiques
            logger.info("üß† Chargement mod√®le d'embeddings...")
            self.embedding_model = SentenceTransformer(
                'all-MiniLM-L6-v2',
                device=self.device
            )
            
            # 4. Classificateur sp√©cialis√© sant√© mentale
            logger.info("üè• Chargement classificateur sant√© mentale...")
            self.mental_health_classifier = pipeline(
                "text-classification",
                model="mental/mental-bert-base-uncased",
                device=0 if self.device == "cuda" else -1,
                return_all_scores=True
            )
            
            logger.info("‚úÖ Tous les mod√®les d'IA charg√©s avec succ√®s")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement mod√®les: {e}")
            # Fallback vers mod√®les plus simples
            self._initialize_fallback_models()
    
    def _initialize_fallback_models(self):
        """Initialise des mod√®les de fallback plus simples"""
        logger.info("üîÑ Chargement mod√®les de fallback...")
        
        try:
            # Mod√®le de sentiment simple
            self.sentiment_analyzer = pipeline(
                "sentiment-analysis",
                model="distilbert-base-uncased-finetuned-sst-2-english",
                device=0 if self.device == "cuda" else -1
            )
            
            # Mod√®le d'embeddings simple
            self.embedding_model = SentenceTransformer(
                'all-MiniLM-L6-v2',
                device=self.device
            )
            
            logger.info("‚úÖ Mod√®les de fallback charg√©s")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur mod√®les fallback: {e}")
            self.sentiment_analyzer = None
            self.embedding_model = None
    
    async def analyze_mental_health(
        self, 
        text: str,
        cultural_context: str = "western",
        language: str = "en"
    ) -> Dict[str, Any]:
        """
        Analyse compl√®te de sant√© mentale avec IA
        """
        start_time = time.time()
        
        try:
            # Pr√©processing du texte
            cleaned_text = self._preprocess_text(text)
            
            if not cleaned_text:
                return self._generate_default_analysis()
            
            # Analyses en parall√®le
            results = {}
            
            # 1. Analyse de sentiment
            sentiment_result = await self._analyze_sentiment(cleaned_text)
            results['sentiment'] = sentiment_result
            
            # 2. Analyse d'√©motions
            emotion_result = await self._analyze_emotions(cleaned_text)
            results['emotions'] = emotion_result
            
            # 3. D√©tection de mots-cl√©s de sant√© mentale
            keywords_result = await self._analyze_mental_health_keywords(cleaned_text)
            results['keywords'] = keywords_result
            
            # 4. Analyse s√©mantique
            semantic_result = await self._analyze_semantic_patterns(cleaned_text)
            results['semantic'] = semantic_result
            
            # 5. Classification sant√© mentale
            mental_health_result = await self._classify_mental_health(cleaned_text)
            results['mental_health_classification'] = mental_health_result
            
            # Fusion des r√©sultats
            final_analysis = await self._fuse_analysis_results(results, cultural_context)
            
            # Ajout des m√©tadonn√©es
            final_analysis['processing_time_ms'] = int((time.time() - start_time) * 1000)
            final_analysis['ai_powered'] = True
            final_analysis['models_used'] = self._get_models_info()
            final_analysis['cultural_context'] = cultural_context
            final_analysis['language'] = language
            
            return final_analysis
            
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse IA: {e}")
            return self._generate_error_analysis(str(e))
    
    async def _analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """Analyse de sentiment avec Transformers"""
        if not self.sentiment_analyzer:
            return {"score": 0.5, "label": "NEUTRAL", "confidence": 0.1}
        
        try:
            # D√©couper le texte si trop long
            chunks = self._split_text(text, max_length=512)
            sentiment_scores = []
            
            for chunk in chunks:
                result = self.sentiment_analyzer(chunk)[0]
                
                # Normaliser les labels selon le mod√®le
                if result['label'] in ['POSITIVE', 'POS']:
                    score = result['score']
                elif result['label'] in ['NEGATIVE', 'NEG']:
                    score = -result['score']
                else:  # NEUTRAL
                    score = 0.0
                
                sentiment_scores.append(score)
            
            # Moyenne pond√©r√©e
            avg_sentiment = np.mean(sentiment_scores) if sentiment_scores else 0.0
            
            # Convertir en score de risque (sentiment n√©gatif = risque √©lev√©)
            risk_score = max(0.0, -avg_sentiment)  # Inverser pour le risque
            
            return {
                "sentiment_score": avg_sentiment,
                "risk_contribution": risk_score,
                "confidence": 0.8,
                "interpretation": self._interpret_sentiment(avg_sentiment)
            }
            
        except Exception as e:
            logger.error(f"Erreur analyse sentiment: {e}")
            return {"sentiment_score": 0.0, "risk_contribution": 0.3, "confidence": 0.1}
    
    async def _analyze_emotions(self, text: str) -> Dict[str, Any]:
        """Analyse d'√©motions avec mod√®le sp√©cialis√©"""
        if not self.emotion_classifier:
            return {"emotions": {}, "risk_contribution": 0.3}
        
        try:
            chunks = self._split_text(text, max_length=512)
            emotion_scores = {}
            
            for chunk in chunks:
                results = self.emotion_classifier(chunk)
                
                for result in results:
                    emotion = result['label'].lower()
                    score = result['score']
                    
                    if emotion in emotion_scores:
                        emotion_scores[emotion] += score
                    else:
                        emotion_scores[emotion] = score
            
            # Normaliser les scores
            total_score = sum(emotion_scores.values())
            if total_score > 0:
                emotion_scores = {k: v/total_score for k, v in emotion_scores.items()}
            
            # Calculer contribution au risque
            risk_emotions = ['sadness', 'fear', 'anger', 'disgust']
            risk_contribution = sum(
                emotion_scores.get(emotion, 0.0) * 0.8 
                for emotion in risk_emotions
            )
            
            return {
                "emotions": emotion_scores,
                "risk_contribution": min(risk_contribution, 1.0),
                "dominant_emotion": max(emotion_scores, key=emotion_scores.get) if emotion_scores else "neutral"
            }
            
        except Exception as e:
            logger.error(f"Erreur analyse √©motions: {e}")
            return {"emotions": {}, "risk_contribution": 0.3}
    
    async def _analyze_mental_health_keywords(self, text: str) -> Dict[str, Any]:
        """D√©tection de mots-cl√©s sp√©cifiques √† la sant√© mentale"""
        
        # Dictionnaires de mots-cl√©s par condition
        mental_health_keywords = {
            'depression': [
                'd√©prim', 'triste', 'vide', 'd√©sespoir', 'inutile', 'fatigue',
                'sans √©nergie', 'plus rien', '√† quoi bon', 'fardeau',
                'depressed', 'sad', 'empty', 'hopeless', 'worthless', 'tired'
            ],
            'anxiety': [
                'anxie', 'stress', 'inquiet', 'panique', 'peur', 'nerveux',
                'angoisse', 'tension', 'pr√©occup', 'catastrophe',
                'anxious', 'worried', 'panic', 'scared', 'nervous', 'stress'
            ],
            'ptsd': [
                'trauma', 'cauchemar', 'flashback', 'reviv', '√©vite', 'd√©clench√©',
                'hypervigilant', 'sursaut', 'intrusi',
                'nightmare', 'flashback', 'triggered', 'hypervigilant', 'intrusive'
            ],
            'suicidal_ideation': [
                'suicide', 'mourir', 'dispara√Ætre', 'en finir', 'plus vivre',
                'mieux mort', 'kill myself', 'want to die', 'end it all'
            ],
            'self_harm': [
                'me faire mal', 'me bless', 'couper', 'br√ªl', 'automutilation',
                'hurt myself', 'cut myself', 'self harm', 'self-harm'
            ]
        }
        
        text_lower = text.lower()
        detected_keywords = {}
        risk_scores = {}
        
        for condition, keywords in mental_health_keywords.items():
            matches = 0
            matched_words = []
            
            for keyword in keywords:
                if keyword in text_lower:
                    matches += text_lower.count(keyword)
                    matched_words.append(keyword)
            
            if matches > 0:
                detected_keywords[condition] = {
                    'count': matches,
                    'words': matched_words
                }
                
                # Score de risque bas√© sur la condition
                if condition in ['suicidal_ideation', 'self_harm']:
                    risk_scores[condition] = min(matches * 0.8, 1.0)  # Tr√®s √©lev√©
                elif condition in ['depression', 'anxiety', 'ptsd']:
                    risk_scores[condition] = min(matches * 0.3, 1.0)  # Mod√©r√© √† √©lev√©
        
        # Calcul du risque global
        max_risk = max(risk_scores.values()) if risk_scores else 0.0
        
        return {
            'detected_keywords': detected_keywords,
            'condition_risks': risk_scores,
            'risk_contribution': max_risk,
            'crisis_indicators': bool(
                'suicidal_ideation' in detected_keywords or 
                'self_harm' in detected_keywords
            )
        }
    
    async def _analyze_semantic_patterns(self, text: str) -> Dict[str, Any]:
        """Analyse s√©mantique avec embeddings"""
        if not self.embedding_model:
            return {"semantic_similarity": {}, "risk_contribution": 0.2}
        
        try:
            # Phrases de r√©f√©rence pour diff√©rentes conditions
            reference_patterns = {
                'depression': [
                    "Je me sens compl√®tement vide et sans espoir",
                    "I feel completely empty and hopeless",
                    "Rien ne me fait plus plaisir, tout semble inutile"
                ],
                'anxiety': [
                    "Je m'inqui√®te constamment de tout ce qui pourrait mal se passer",
                    "I constantly worry about everything that could go wrong",
                    "Mon c≈ìur bat tr√®s fort et j'ai du mal √† respirer"
                ],
                'crisis': [
                    "Je ne peux plus supporter cette douleur",
                    "I can't take this pain anymore",
                    "Il vaudrait mieux que je ne sois plus l√†"
                ]
            }
            
            # Obtenir l'embedding du texte
            text_embedding = self.embedding_model.encode([text])
            similarities = {}
            
            for condition, patterns in reference_patterns.items():
                pattern_embeddings = self.embedding_model.encode(patterns)
                
                # Calculer similarit√© cosinus moyenne
                similarities_scores = []
                for pattern_emb in pattern_embeddings:
                    similarity = np.dot(text_embedding[0], pattern_emb) / (
                        np.linalg.norm(text_embedding[0]) * np.linalg.norm(pattern_emb)
                    )
                    similarities_scores.append(max(0, similarity))  # Garder seulement positif
                
                similarities[condition] = np.mean(similarities_scores)
            
            # Calcul du risque bas√© sur les similarit√©s
            max_similarity = max(similarities.values()) if similarities else 0.0
            risk_contribution = max_similarity * 0.7  # Mod√©rer l'impact
            
            return {
                "semantic_similarities": similarities,
                "risk_contribution": risk_contribution,
                "closest_pattern": max(similarities, key=similarities.get) if similarities else None
            }
            
        except Exception as e:
            logger.error(f"Erreur analyse s√©mantique: {e}")
            return {"semantic_similarities": {}, "risk_contribution": 0.2}
    
    async def _classify_mental_health(self, text: str) -> Dict[str, Any]:
        """Classification avec mod√®le sp√©cialis√© sant√© mentale"""
        if not self.mental_health_classifier:
            return {"classifications": {}, "risk_contribution": 0.3}
        
        try:
            # Utiliser le classificateur si disponible
            results = self.mental_health_classifier(text)
            
            classifications = {}
            if results and isinstance(results, list):
                for result in results[0]:  # Premier r√©sultat
                    label = result['label'].lower()
                    score = result['score']
                    classifications[label] = score
            
            # Calculer contribution au risque
            risk_labels = ['depression', 'anxiety', 'stress', 'suicidal']
            risk_contribution = sum(
                classifications.get(label, 0.0) * 0.6
                for label in risk_labels
            )
            
            return {
                "classifications": classifications,
                "risk_contribution": min(risk_contribution, 1.0)
            }
            
        except Exception as e:
            logger.error(f"Erreur classification sant√© mentale: {e}")
            return {"classifications": {}, "risk_contribution": 0.3}
    
    async def _fuse_analysis_results(
        self, 
        results: Dict[str, Any],
        cultural_context: str
    ) -> Dict[str, Any]:
        """Fusionne tous les r√©sultats d'analyse"""
        
        # Extraction des contributions au risque
        risk_components = {
            'sentiment': results.get('sentiment', {}).get('risk_contribution', 0.3),
            'emotions': results.get('emotions', {}).get('risk_contribution', 0.3),
            'keywords': results.get('keywords', {}).get('risk_contribution', 0.2),
            'semantic': results.get('semantic', {}).get('risk_contribution', 0.2),
            'classification': results.get('mental_health_classification', {}).get('risk_contribution', 0.3)
        }
        
        # Poids pour la fusion (ajustables selon le contexte culturel)
        weights = {
            'sentiment': 0.25,
            'emotions': 0.25,
            'keywords': 0.25,
            'semantic': 0.15,
            'classification': 0.10
        }
        
        # Ajustements culturels
        if cultural_context == "collectivist":
            weights['semantic'] += 0.05  # Plus d'importance au contexte
            weights['sentiment'] -= 0.05
        
        # Calcul du score de risque fusionn√©
        overall_risk = sum(
            risk_components[component] * weights[component]
            for component in risk_components
        )
        
        # D√©termination du niveau de risque
        if overall_risk < 0.25:
            risk_level = "low"
        elif overall_risk < 0.5:
            risk_level = "moderate"
        elif overall_risk < 0.75:
            risk_level = "high"
        else:
            risk_level = "critical"
        
        # D√©tection de crise
        crisis_detected = results.get('keywords', {}).get('crisis_indicators', False)
        if crisis_detected:
            risk_level = "critical"
            overall_risk = max(overall_risk, 0.9)
        
        # Conditions probables
        condition_probabilities = self._calculate_condition_probabilities(results)
        
        # Confiance globale
        confidence_scores = [
            results.get('sentiment', {}).get('confidence', 0.5),
            0.8 if results.get('emotions', {}).get('emotions') else 0.3,
            0.9 if results.get('keywords', {}).get('detected_keywords') else 0.2,
            0.7 if results.get('semantic', {}).get('semantic_similarities') else 0.3
        ]
        overall_confidence = np.mean(confidence_scores)
        
        # Suggestions bas√©es sur l'analyse
        suggestions = self._generate_ai_suggestions(results, risk_level)
        
        return {
            'overall_risk_score': min(max(overall_risk, 0.0), 1.0),
            'risk_level': risk_level,
            'confidence_score': overall_confidence,
            'condition_probabilities': condition_probabilities,
            'risk_components': risk_components,
            'detailed_analysis': results,
            'suggestions': suggestions,
            'crisis_detected': crisis_detected,
            'privacy_protected': True
        }
    
    def _calculate_condition_probabilities(self, results: Dict[str, Any]) -> Dict[str, float]:
        """Calcule les probabilit√©s pour chaque condition"""
        
        conditions = {
            'depression': 0.0,
            'anxiety': 0.0,
            'ptsd': 0.0,
            'bipolar': 0.0,
            'burnout': 0.0
        }
        
        # Bas√© sur les √©motions
        emotions = results.get('emotions', {}).get('emotions', {})
        if 'sadness' in emotions:
            conditions['depression'] += emotions['sadness'] * 0.8
        if 'fear' in emotions:
            conditions['anxiety'] += emotions['fear'] * 0.7
        if 'anger' in emotions:
            conditions['ptsd'] += emotions['anger'] * 0.4
            conditions['bipolar'] += emotions['anger'] * 0.3
        
        # Bas√© sur les mots-cl√©s
        keywords = results.get('keywords', {}).get('condition_risks', {})
        for condition, risk in keywords.items():
            if condition in conditions:
                conditions[condition] += risk * 0.6
        
        # Bas√© sur les similarit√©s s√©mantiques
        semantic = results.get('semantic', {}).get('semantic_similarities', {})
        for pattern, similarity in semantic.items():
            if pattern in conditions:
                conditions[pattern] += similarity * 0.5
        
        # Normalisation et ajout d'un minimum
        for condition in conditions:
            conditions[condition] = min(max(conditions[condition], 0.05), 1.0)
        
        return conditions
    
    def _generate_ai_suggestions(self, results: Dict[str, Any], risk_level: str) -> List[str]:
        """G√©n√®re des suggestions bas√©es sur l'analyse IA"""
        
        suggestions = []
        
        if risk_level == "critical":
            suggestions.extend([
                "üö® Contacter imm√©diatement un professionnel de sant√© mentale",
                "‚òéÔ∏è Appeler une ligne d'√©coute : 3114 (gratuit, 24h/24)",
                "üÜò En cas d'urgence : 15 (SAMU) ou 112"
            ])
        elif risk_level == "high":
            suggestions.extend([
                "üë®‚Äç‚öïÔ∏è Consulter un professionnel de sant√© mentale",
                "üîÑ Pratiquer des exercices de respiration quotidiens",
                "üí¨ Parler √† un proche de confiance"
            ])
        elif risk_level == "moderate":
            suggestions.extend([
                "üßò Int√©grer la m√©ditation dans votre routine",
                "üìù Tenir un journal de vos √©motions",
                "üèÉ‚Äç‚ôÄÔ∏è Maintenir une activit√© physique r√©guli√®re"
            ])
        else:  # low
            suggestions.extend([
                "üòå Continuer vos pratiques de bien-√™tre actuelles",
                "üìÖ Programmer des check-ins r√©guliers avec vous-m√™me",
                "üå± Explorer de nouvelles activit√©s enrichissantes"
            ])
        
        # Suggestions sp√©cifiques aux √©motions d√©tect√©es
        emotions = results.get('emotions', {}).get('emotions', {})
        dominant_emotion = results.get('emotions', {}).get('dominant_emotion')
        
        if dominant_emotion == 'anxiety' or 'fear' in emotions:
            suggestions.append("üå¨Ô∏è Technique de respiration 4-7-8 recommand√©e")
        
        if dominant_emotion == 'sadness':
            suggestions.append("‚òÄÔ∏è Exposition √† la lumi√®re naturelle b√©n√©fique")
        
        return suggestions[:5]  # Limiter √† 5 suggestions
    
    def _preprocess_text(self, text: str) -> str:
        """Pr√©processe le texte pour l'analyse"""
        if not text or not isinstance(text, str):
            return ""
        
        # Nettoyage basique
        text = re.sub(r'http\S+|www\S+|https\S+', '', text)  # URLs
        text = re.sub(r'@\w+|#\w+', '', text)  # Mentions et hashtags
        text = re.sub(r'\s+', ' ', text)  # Espaces multiples
        text = text.strip()
        
        return text
    
    def _split_text(self, text: str, max_length: int = 512) -> List[str]:
        """D√©coupe le texte en chunks pour les mod√®les"""
        if len(text) <= max_length:
            return [text]
        
        # D√©couper par phrases si possible
        sentences = text.split('. ')
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk + sentence) <= max_length:
                current_chunk += sentence + ". "
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + ". "
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks or [text[:max_length]]
    
    def _interpret_sentiment(self, sentiment_score: float) -> str:
        """Interpr√®te le score de sentiment"""
        if sentiment_score > 0.3:
            return "Sentiment majoritairement positif"
        elif sentiment_score > -0.3:
            return "Sentiment neutre"
        else:
            return "Sentiment majoritairement n√©gatif"
    
    def _generate_default_analysis(self) -> Dict[str, Any]:
        """G√©n√®re une analyse par d√©faut"""
        return {
            'overall_risk_score': 0.3,
            'risk_level': 'moderate',
            'confidence_score': 0.1,
            'condition_probabilities': {
                'depression': 0.2,
                'anxiety': 0.2,
                'ptsd': 0.1,
                'bipolar': 0.1,
                'burnout': 0.2
            },
            'suggestions': [
                "Texte insuffisant pour une analyse compl√®te",
                "Essayez de d√©crire plus en d√©tail votre √©tat"
            ],
            'processing_time_ms': 10,
            'ai_powered': False
        }
    
    def _generate_error_analysis(self, error_msg: str) -> Dict[str, Any]:
        """G√©n√®re une analyse d'erreur s√©curis√©e"""
        return {
            'overall_risk_score': 0.3,
            'risk_level': 'moderate',
            'confidence_score': 0.1,
            'condition_probabilities': {
                'depression': 0.2,
                'anxiety': 0.2,
                'ptsd': 0.1,
                'bipolar': 0.1,
                'burnout': 0.2
            },
            'suggestions': [
                "Erreur lors de l'analyse - utilisation de valeurs par d√©faut",
                "Veuillez r√©essayer ou contacter le support"
            ],
            'processing_time_ms': 5,
            'ai_powered': False,
            'error': "Erreur d'analyse IA",
            'privacy_protected': True
        }
    
    def _get_models_info(self) -> Dict[str, str]:
        """Retourne les informations sur les mod√®les utilis√©s"""
        return {
            'sentiment': "cardiffnlp/twitter-roberta-base-sentiment-latest" if self.sentiment_analyzer else "None",
            'emotion': "j-hartmann/emotion-english-distilroberta-base" if self.emotion_classifier else "None",
            'embedding': "all-MiniLM-L6-v2" if self.embedding_model else "None",
            'mental_health': "mental/mental-bert-base-uncased" if self.mental_health_classifier else "None"
        }
    
    def get_model_status(self) -> Dict[str, Any]:
        """Retourne le statut des mod√®les"""
        return {
            'device': self.device,
            'models_loaded': {
                'sentiment_analyzer': self.sentiment_analyzer is not None,
                'emotion_classifier': self.emotion_classifier is not None,
                'embedding_model': self.embedding_model is not None,
                'mental_health_classifier': self.mental_health_classifier is not None
            },
            'memory_usage': torch.cuda.memory_allocated() if torch.cuda.is_available() else "N/A",
            'ready': any([
                self.sentiment_analyzer,
                self.emotion_classifier,
                self.embedding_model
            ])
        }

# Instance globale
mental_health_ai = None

def get_mental_health_ai() -> MentalHealthAI:
    """Retourne l'instance singleton du moteur IA"""
    global mental_health_ai
    if mental_health_ai is None:
        mental_health_ai = MentalHealthAI()
    return mental_health_ai